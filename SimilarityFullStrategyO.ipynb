{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "708b9f0b-9305-4e07-845c-59aeccd856b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "import requests\n",
    "from IPython.display import JSON\n",
    "import numpy as np\n",
    "from fuzzywuzzy import fuzz\n",
    "from joblib import Parallel, delayed\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "from sklearn import metrics\n",
    "import math\n",
    "from thefuzz import fuzz, process\n",
    "import re\n",
    "from IPython.display import clear_output, display\n",
    "import json\n",
    "from unidecode import unidecode\n",
    "#from colavsim import colav_similarity, parse_doi, parse_string\n",
    "import sys\n",
    "from hunahpu.Similarity import parse_string, ColavSimilarity as  colav_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40bbd96-3f2a-4f22-a125-f31a3fccc757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk import ngrams\n",
    "# from unidecode import unidecode\n",
    "# from thefuzz import fuzz, process\n",
    "# from langid import classify\n",
    "# from googletrans import Translator\n",
    "\n",
    "# import re\n",
    "\n",
    "\n",
    "# def __parse_string(text):\n",
    "#     '''\n",
    "#     This function allows to remove unneeded characters\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     text : str\n",
    "#         text to parse\n",
    "#     '''\n",
    "#     data = str(text).lower()\n",
    "#     data = re.sub(r'<[^>]+>', '', data)\n",
    "#     data = re.sub(r'[\\$_\\^]', '', re.sub(r'\\\\\\w+', '', data))\n",
    "#     data = unidecode(data)\n",
    "#     return data\n",
    "\n",
    "# def parse_string(text):\n",
    "#     return __parse_string(text)\n",
    "\n",
    "\n",
    "\n",
    "# def __colav_similarity(\n",
    "#         paper1,\n",
    "#         paper2,\n",
    "#         ratio_thold=90,\n",
    "#         partial_thold=95,\n",
    "#         low_thold=80,\n",
    "#         use_translation=False,\n",
    "#         verbose=0):\n",
    "#     '''\n",
    "#     Utility function to avoid code duplication, public implementation below.\n",
    "#     '''\n",
    "#     label = False\n",
    "\n",
    "#     title1 = paper1['title']\n",
    "#     journal1 = paper1['journal']\n",
    "#     year1 = paper1['year']\n",
    "\n",
    "#     title2 = paper2['title']\n",
    "#     journal2 = paper2['journal']\n",
    "#     year2 = paper2['year']\n",
    "\n",
    "#     year_check = False\n",
    "#     if year1 and year2:\n",
    "#         if year1 == year2:\n",
    "#             year_check = True\n",
    "\n",
    "#     journal_check = False\n",
    "#     if journal1 and journal2:\n",
    "#         if fuzz.partial_ratio(\n",
    "#             unidecode(\n",
    "#                 journal1.lower()), unidecode(\n",
    "#                 journal2.lower())) > ratio_thold:\n",
    "#             journal_check = True\n",
    "\n",
    "#     length_check = False\n",
    "#     if len(title1.split()) >= 1 and len(title2.split()) >= 1:\n",
    "#         length_check = True\n",
    "\n",
    "#     # Si son pocas palabras y no hay por lo menos revista o año para revisar, se descarta de uan vez\n",
    "#     if length_check == False and (journal_check == False or year_check == False):\n",
    "#         return label\n",
    "\n",
    "#     if verbose == 5:\n",
    "#         if journal_check:\n",
    "#             print(\"Journals are the same\")\n",
    "#         if year_check:\n",
    "#             print(\"Years are the same\")\n",
    "\n",
    "#     ratio = fuzz.ratio(title1, title2)\n",
    "#     if verbose == 5:\n",
    "#         print(\"Initial ratio: \", ratio)\n",
    "#     if ratio > ratio_thold and length_check:\n",
    "#         label = True\n",
    "#     else:\n",
    "#         title1_list = title1.split(\"[\")\n",
    "#         title2_list = title2.split(\"[\")\n",
    "#         if min([len(item) for item in title1_list]) > 10 and min([len(item) for item in title2_list]) > 10:\n",
    "#             for title in title1_list:\n",
    "#                 _, ratio = process.extractOne(\n",
    "#                     title, title2_list, scorer=fuzz.ratio)\n",
    "#                 if ratio > ratio_thold:\n",
    "#                     label = True\n",
    "#                     break\n",
    "#             if verbose == 5:\n",
    "#                 print(\"ratio over list: \", ratio)\n",
    "#             if not label:\n",
    "#                 for title in title1_list:\n",
    "#                     _, ratio = process.extractOne(\n",
    "#                         title, title2_list, scorer=fuzz.partial_ratio)\n",
    "#                     if ratio > partial_thold:\n",
    "#                         label = True\n",
    "#                         break\n",
    "#                     elif ratio > low_thold:\n",
    "#                         if journal_check and year_check:\n",
    "#                             label = True\n",
    "#                             break\n",
    "#                 if verbose == 5:\n",
    "#                     print(\"partial ratio over list: \", ratio)\n",
    "\n",
    "#     # Partial ratio section\n",
    "#     if label == False:\n",
    "\n",
    "#         ratio = fuzz.partial_ratio(title1, title2)\n",
    "#         if verbose == 5:\n",
    "#             print(\"partial ratio: \", ratio)\n",
    "\n",
    "#         if ratio > partial_thold and length_check:\n",
    "#             label = True\n",
    "#         elif ratio > low_thold:\n",
    "#             if journal_check and year_check:\n",
    "#                 label = True\n",
    "\n",
    "#     # Translation section\n",
    "#     if label is False and use_translation:\n",
    "#         lang1, _ = classify(title1)\n",
    "#         lang2, _ = classify(title2)\n",
    "#         if lang1 != \"en\" or lang2 != \"en\":\n",
    "#             if lang1 != \"en\":\n",
    "#                 translator = Translator()\n",
    "#                 try:\n",
    "#                     title1 = translator.translate(title1).text\n",
    "#                 except Exception as e:\n",
    "#                     if verbose == 5:\n",
    "#                         print(e)\n",
    "#                 if verbose == 5:\n",
    "#                     print(\"Title 1 translated to \", title1)\n",
    "#             if lang2 != \"en\":\n",
    "#                 translator = Translator()\n",
    "#                 try:\n",
    "#                     title2 = translator.translate(title2).text\n",
    "#                 except Exception as e:\n",
    "#                     print(e)\n",
    "#                 if verbose == 5:\n",
    "#                     print(\"Title 2 translated to \", title2)\n",
    "\n",
    "#             ratio = fuzz.ratio(title1, title2)\n",
    "#             if verbose == 5:\n",
    "#                 print(\"Ratio over translation: \", ratio)\n",
    "#             if ratio > ratio_thold:\n",
    "#                 label = True\n",
    "#             if label is False:\n",
    "#                 ratio = fuzz.partial_ratio(title1, title2)\n",
    "#                 if verbose == 5:\n",
    "#                     print(\"partial ratio over translation: \", ratio)\n",
    "#                 if ratio > partial_thold:\n",
    "#                     label = True\n",
    "#                 elif ratio > low_thold:\n",
    "#                     if journal_check and year_check:\n",
    "#                         label = True\n",
    "\n",
    "#     return label\n",
    "\n",
    "\n",
    "# def colav_similarity(\n",
    "#         paper1,\n",
    "#         paper2,\n",
    "#         ratio_thold=96,\n",
    "#         partial_thold=98,\n",
    "#         low_thold=76,\n",
    "#         use_translation=False,\n",
    "#         use_parsing=True):\n",
    "#     '''\n",
    "#     custom metric for similarity using multiple nested metrics from fuzzywuzzy\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     paper1: dictionary\n",
    "#         dictionary with keys title,journal and year is required\n",
    "#     paper2: dictionary\n",
    "#         dictionary with keys title,journal and year is required\n",
    "#     ratio_thold: int\n",
    "#         threshold for  ratio matric\n",
    "#     partial_thold: int\n",
    "#         threshold for partial ratio\n",
    "#     low_thold: int\n",
    "#         low threshold for ratios\n",
    "#     use_translation : str\n",
    "#         enable translation support\n",
    "#     use_parsing: boolean\n",
    "#         use parsing to remove unneeded characters\n",
    "#     '''\n",
    "\n",
    "#     if paper1['title']  is None:\n",
    "#         paper1['title']  = \"\"\n",
    "#     if paper2['title']  is None:\n",
    "#         paper2['title']  = \"\"\n",
    "#     if not isinstance(paper1['journal'], str):\n",
    "#         paper1['journal'] = str(paper1['journal'])\n",
    "#     if not isinstance(paper2['journal'], str):\n",
    "#         paper2['journal'] = str(paper2['journal'])\n",
    "\n",
    "#     paper1['title'] = unidecode(paper1['title'].lower())\n",
    "#     paper2['title'] = unidecode(paper2['title'].lower())\n",
    "\n",
    "#     if paper1['year']:\n",
    "#         paper1['year'] = int(paper1['year'])\n",
    "#     if paper2['year']:\n",
    "#         paper2['year'] = int(paper2['year'])\n",
    "\n",
    "#     label = False\n",
    "\n",
    "#     if not use_parsing:\n",
    "#         label = __colav_similarity(\n",
    "#             paper1,\n",
    "#             paper2,\n",
    "#             ratio_thold,\n",
    "#             partial_thold,\n",
    "#             low_thold,\n",
    "#             use_translation)\n",
    "#     elif use_parsing:\n",
    "#         paper1['title'] = __parse_string(paper1['title'])\n",
    "#         paper2['title'] = __parse_string(paper2['title'])\n",
    "#         label = __colav_similarity(\n",
    "#             paper1,\n",
    "#             paper2,\n",
    "#             ratio_thold,\n",
    "#             partial_thold,\n",
    "#             low_thold,\n",
    "#             use_translation)\n",
    "#     return label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85c9b460-8582-4449-992c-04ce74d3ccfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch(host=\"172.19.31.8\",timeout=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4743a24f-e166-4894-8177-dbe6c52814a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a file, where you stored the pickled data\n",
    "file = open('dataset_full.pkl', 'rb')\n",
    "# dump information to that file\n",
    "data = pickle.load(file)\n",
    "# close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ead3c6c0-b35e-4455-9a6a-5b764337a5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101773"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[\"p\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "345fb1b9-d27e-4d48-bf6b-a5421f8c8c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41596"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[\"n\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e93091a-83f7-44c7-a1d1-285b6adbefdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_array', 'openalex_parsed', 'openalex_scratch', 'openalex_raw']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_984606/1562848919.py:1: DeprecationWarning: Using positional arguments for APIs is deprecated and will be disabled in 8.0.0. Instead use only keyword arguments for all APIs. See https://github.com/elastic/elasticsearch-py/issues/1698 for more information\n",
      "  es_index = list(es.indices.get_alias(\"*\").keys())\n"
     ]
    }
   ],
   "source": [
    "es_index = list(es.indices.get_alias(\"*\").keys())\n",
    "print(es_index)\n",
    "#es_index.remove(\"openalex_raw\")\n",
    "#es_index.remove(\"openalex_dfr\")\n",
    "es_index = \"openalex_parsed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe1c796-c132-4f5d-980f-d902740b8706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6058f012-1ece-40f8-ad7a-85c610d908ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oa_doi(es_reg):\n",
    "    for i in es_reg[\"_source\"]['external_ids']:\n",
    "        if i['source'] == \"doi\":\n",
    "            return i[\"id\"]\n",
    "\n",
    "\n",
    "def get_oa_doi(es_reg):\n",
    "    return es_reg[\"_source\"]['doi']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9579759a-ea77-4b5d-8552-997ebad85c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(Title, Authors:list, Source:str, Year:str, Volume:str, Issue:str, PageStart:str, PageEnd:str):\n",
    "    \"\"\"\n",
    "    Definir el valor mínimo del _score que deseas\n",
    "    Puedes ajustar este valor según tus necesidades\n",
    "\n",
    "    \"\"\"\n",
    "    if not isinstance(Volume, str) or not isinstance(Volume, int):\n",
    "        Volume = \"\"\n",
    "    if not isinstance(Issue, str) or not isinstance(Issue, int):\n",
    "        Issue = \"\"\n",
    "    if not isinstance(PageStart, str) or not isinstance(PageStart, int):\n",
    "        PageStart = \"\"\n",
    "    if not isinstance(PageEnd, str) or not isinstance(PageEnd, int):\n",
    "        PageEnd = \"\"\n",
    "\n",
    "#    should = [      { \"term\": { \"year\": Year }},\n",
    "#     should = [      { \"match\": { \"year\":  { \n",
    "#                                  \"query\": Year,\n",
    "#                                  \"boost\": 16\n",
    "#                               }}},\n",
    "#                     { \"term\": { \"volume\": Volume }},\n",
    "#                     { \"term\": { \"issue\": Issue }},\n",
    "#                     { \"term\": { \"first_page\": PageStart }},\n",
    "#                     { \"term\": { \"last_page\": PageEnd }}]\n",
    "    \n",
    "#     if isinstance(Titles, list) :\n",
    "#         for title in Titles:\n",
    "#             should.append(\n",
    "#             { \"match\": { \"title\": {\"query\": title, \n",
    "#                                    \"boost\": 0.8,}}}\n",
    "#             )\n",
    "#     else:\n",
    "#         print(\"Error, Titles should be list\")\n",
    "#         sys.exit(1)\n",
    "    authors = []\n",
    "    if isinstance(Authors, list) :\n",
    "        for author in Authors:\n",
    "            authors.append(\n",
    "                    { \"match\": { \"authors\":  {\n",
    "                                 \"query\": author,\n",
    "                                 \"operator\": \"AND\",\n",
    "                                 # \"boost\": 2\n",
    "                              }}}            \n",
    "            )\n",
    "        Authors = \" \".join(Authors)\n",
    "    else:\n",
    "        print(\"Error, Authors should be list\")\n",
    "        sys.exit(1)\n",
    "#     if Source:\n",
    "#         should.append({ \"match\": { \"source\":  {\n",
    "#                                  \"query\": str(Source),\n",
    "#                                  \"operator\": \"AND\",\n",
    "#                                  \"boost\": 2\n",
    "#                               }}},)\n",
    "    # if not isinstance(Source, str) and not None:\n",
    "    #     Source = \"\"\n",
    "    body = {\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"should\": \n",
    "                [\n",
    "                    # { \"match\": { \"title\":  {\n",
    "                    #              \"query\": Title,\n",
    "                    #              \"operator\": \"OR\"\n",
    "                    #           }}},\n",
    "                     #{ \"match_phrase\": { \"title\": { \"query\": Title, \"boost\": 0.8 }}},\n",
    "                    { \"match\": { \"title\": { \n",
    "                                            \"query\": Title, \n",
    "                                            \"boost\": 0.8,}}},\n",
    "                    #{ \"match\": { \"authors\":  Authors }},# se tienen que truncar los autores \n",
    "                    # { \"match\": { \"authors\":  {\n",
    "                    #              \"query\": Authors,\n",
    "                    #              \"operator\": \"AND\",\n",
    "                    #              # \"boost\": 2\n",
    "                    #           }}},\n",
    "                    { \"match\": { \"source\":  {\n",
    "                                 \"query\": Source,\n",
    "                                 \"operator\": \"AND\",\n",
    "                                 # \"boost\": 2\n",
    "                              }}},\n",
    "                    # { \"match\": { \"year\":  { # term can not be boosted, , the contribution to the score is too small, it should be boosted a lotand them it has to be match\n",
    "                    #              \"query\": Year,\n",
    "                    #              \"boost\": 16\n",
    "                    #           }}},\n",
    "                    # { \"match\": { \"volume\":  {\n",
    "                    #              \"query\": Volume,\n",
    "                    #              \"boost\": nterms\n",
    "                    #           }}},\n",
    "                    # { \"match\": { \"issue\":  {\n",
    "                    #              \"query\": Issue,\n",
    "                    #              \"boost\": nterms\n",
    "                    #           }}},\n",
    "                    # { \"match\": { \"first_page\":  {\n",
    "                    #              \"query\": PageStart,\n",
    "                    #              \"boost\": nterms\n",
    "                    #           }}},\n",
    "                    # { \"match\": { \"last_page\":  {\n",
    "                    #              \"query\": PageEnd,\n",
    "                    #              \"boost\": nterms\n",
    "                    #           }}},\n",
    "                    { \"term\": { \"year\": Year }},\n",
    "                    { \"term\": { \"volume\": Volume }},\n",
    "                    { \"term\": { \"issue\": Issue }},\n",
    "                    { \"term\": { \"first_page\": PageStart }},\n",
    "                    { \"term\": { \"last_page\": PageEnd }},\n",
    "                    \n",
    "                ] ,\n",
    "            }\n",
    "        },\n",
    "        \"size\": 20\n",
    "    }\n",
    "    body[\"query\"][\"bool\"][\"should\"].extend(authors)\n",
    "    res = es.search(index=es_index, **body)\n",
    "    return  res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b535edfe-b85b-4555-a0bc-1892addfb135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def parse_string(string:str):\n",
    "#     data = str(string).lower()\n",
    "#     data = re.sub(r'<[^>]+>','',data)\n",
    "#     data = unidecode(data)\n",
    "#     return data    \n",
    "# def parse_doi(doi):\n",
    "    \n",
    "#     return re.sub(r'https*\\:\\/\\/[\\w\\.]+\\/','',str(doi).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c81680b0-1e0b-4a5b-962b-3b17c341edda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=72)]: Using backend ThreadingBackend with 72 concurrent workers.\n",
      "[Parallel(n_jobs=72)]: Done  18 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=72)]: Done 221 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=72)]: Done 504 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=72)]: Done 869 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=72)]: Done 1314 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=72)]: Done 1841 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=72)]: Done 2448 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=72)]: Done 3137 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=72)]: Done 3906 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=72)]: Done 4757 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=72)]: Done 5688 tasks      | elapsed:   23.6s\n",
      "[Parallel(n_jobs=72)]: Done 6701 tasks      | elapsed:   28.2s\n",
      "[Parallel(n_jobs=72)]: Done 7794 tasks      | elapsed:   33.0s\n",
      "[Parallel(n_jobs=72)]: Done 8969 tasks      | elapsed:   37.9s\n",
      "[Parallel(n_jobs=72)]: Done 10224 tasks      | elapsed:   43.6s\n",
      "[Parallel(n_jobs=72)]: Done 11561 tasks      | elapsed:   49.5s\n",
      "[Parallel(n_jobs=72)]: Done 12978 tasks      | elapsed:   55.8s\n",
      "[Parallel(n_jobs=72)]: Done 14477 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=72)]: Done 16056 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=72)]: Done 17717 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=72)]: Done 19458 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=72)]: Done 21281 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=72)]: Done 23184 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=72)]: Done 25169 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=72)]: Done 27234 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=72)]: Done 29381 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=72)]: Done 31608 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=72)]: Done 33917 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=72)]: Done 36306 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=72)]: Done 38777 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=72)]: Done 41328 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=72)]: Done 43961 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=72)]: Done 46674 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=72)]: Done 49469 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=72)]: Done 52344 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=72)]: Done 55301 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=72)]: Done 58338 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=72)]: Done 61457 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=72)]: Done 64656 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=72)]: Done 67937 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=72)]: Done 71298 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=72)]: Done 74741 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=72)]: Done 78264 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=72)]: Done 81869 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=72)]: Done 85554 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=72)]: Done 89321 tasks      | elapsed:  6.4min\n"
     ]
    },
    {
     "ename": "RequestError",
     "evalue": "RequestError(400, 'x_content_parse_exception', \"[1:404] Non-standard token 'NaN': enable `JsonReadFeature.ALLOW_NON_NUMERIC_NUMBERS` to allow\\n at [Source: (org.elasticsearch.common.io.stream.ByteBufferStreamInput); line: 1, column: 404]\")",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRequestError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:113\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m/usr/lib/python3.9/multiprocessing/pool.py:771\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 771\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m/usr/lib/python3.9/multiprocessing/pool.py:125\u001b[0m, in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    123\u001b[0m job, i, func, args, kwds \u001b[38;5;241m=\u001b[39m task\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 125\u001b[0m     result \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wrap_exception \u001b[38;5;129;01mand\u001b[39;00m func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _helper_reraises_exception:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/_parallel_backends.py:620\u001b[0m, in \u001b[0;36mSafeFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 620\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    622\u001b[0m         \u001b[38;5;66;03m# We capture the KeyboardInterrupt and reraise it as\u001b[39;00m\n\u001b[1;32m    623\u001b[0m         \u001b[38;5;66;03m# something different, as multiprocessing does not\u001b[39;00m\n\u001b[1;32m    624\u001b[0m         \u001b[38;5;66;03m# interrupt processing for a KeyboardInterrupt\u001b[39;00m\n\u001b[1;32m    625\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m WorkerInterrupt() \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m<timed exec>:11\u001b[0m, in \u001b[0;36mes_similarity\u001b[0;34m(rec, th_high, th_low, mode)\u001b[0m\n",
      "Cell \u001b[0;32mIn [8], line 113\u001b[0m, in \u001b[0;36msearch\u001b[0;34m(Title, Authors, Source, Year, Volume, Issue, PageStart, PageEnd)\u001b[0m\n\u001b[1;32m     57\u001b[0m body \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbool\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m20\u001b[39m\n\u001b[1;32m    111\u001b[0m }\n\u001b[1;32m    112\u001b[0m body[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbool\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshould\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mextend(authors)\n\u001b[0;32m--> 113\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mes_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m  res\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/elasticsearch/client/utils.py:301\u001b[0m, in \u001b[0;36mquery_params.<locals>._wrapper.<locals>._wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    300\u001b[0m         params[p] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(p)\n\u001b[0;32m--> 301\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/elasticsearch/client/__init__.py:1765\u001b[0m, in \u001b[0;36mElasticsearch.search\u001b[0;34m(self, body, index, doc_type, params, headers)\u001b[0m\n\u001b[1;32m   1762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m   1763\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m params\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1765\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1766\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1767\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_make_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoc_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_search\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1768\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1769\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1770\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1771\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/elasticsearch/transport.py:458\u001b[0m, in \u001b[0;36mTransport.perform_request\u001b[0;34m(self, method, url, headers, params, body)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;66;03m# connection didn't fail, confirm it's live status\u001b[39;00m\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection_pool\u001b[38;5;241m.\u001b[39mmark_live(connection)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/elasticsearch/transport.py:419\u001b[0m, in \u001b[0;36mTransport.perform_request\u001b[0;34m(self, method, url, headers, params, body)\u001b[0m\n\u001b[1;32m    416\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_connection()\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 419\u001b[0m     status, headers_response, data \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;66;03m# Lowercase all the header names for consistency in accessing them.\u001b[39;00m\n\u001b[1;32m    430\u001b[0m     headers_response \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    431\u001b[0m         header\u001b[38;5;241m.\u001b[39mlower(): value \u001b[38;5;28;01mfor\u001b[39;00m header, value \u001b[38;5;129;01min\u001b[39;00m headers_response\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    432\u001b[0m     }\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/elasticsearch/connection/http_urllib3.py:287\u001b[0m, in \u001b[0;36mUrllib3HttpConnection.perform_request\u001b[0;34m(self, method, url, params, body, timeout, ignore, headers)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ignore:\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_request_fail(\n\u001b[1;32m    285\u001b[0m         method, full_url, url, orig_body, duration, response\u001b[38;5;241m.\u001b[39mstatus, raw_data\n\u001b[1;32m    286\u001b[0m     )\n\u001b[0;32m--> 287\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_request_success(\n\u001b[1;32m    290\u001b[0m     method, full_url, url, orig_body, response\u001b[38;5;241m.\u001b[39mstatus, raw_data, duration\n\u001b[1;32m    291\u001b[0m )\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus, response_headers, raw_data\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/elasticsearch/connection/base.py:337\u001b[0m, in \u001b[0;36mConnection._raise_error\u001b[0;34m(self, status_code, raw_data)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    335\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUndecodable raw error response from server: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, err)\n\u001b[0;32m--> 337\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HTTP_EXCEPTIONS\u001b[38;5;241m.\u001b[39mget(status_code, TransportError)(\n\u001b[1;32m    338\u001b[0m     status_code, error_message, additional_info\n\u001b[1;32m    339\u001b[0m )\n",
      "\u001b[0;31mRequestError\u001b[0m: RequestError(400, 'x_content_parse_exception', \"[1:404] Non-standard token 'NaN': enable `JsonReadFeature.ALLOW_NON_NUMERIC_NUMBERS` to allow\\n at [Source: (org.elasticsearch.common.io.stream.ByteBufferStreamInput); line: 1, column: 404]\")"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#ratio_thold=90, partial_thold=90,low_thold=85) #3000 / fn = 26\n",
    "#ratio_thold=95, partial_thold=90,low_thold=80 #3000 / fn = 25\n",
    "#ratio_thold=90, partial_thold=90,low_thold=80 #3000 / fn = 24\n",
    "#dfr fn = 47 Title, Source year \n",
    "#openalex_parsed fn =37  all fields\n",
    "#openalex_parsed fn = .79  all fields all dataset\n",
    "#openalex_parsed fn = 0.70 fp 6.041  all fields all dataset mode 3\n",
    "\n",
    "\n",
    "def es_similarity(rec,th_high = 0, th_low = 0, mode = 0):\n",
    "    res = search(parse_string(rec[0]['Title']),rec[0]['Authors'].split(\",\")[0:5],rec[0]['Source title'],rec[0]['Year'],\n",
    "    #res = search(parse_string(rec[0]['Title']),\" \".join(rec[0]['Authors'].split(\",\")[0:5]),rec[0]['Source title'],rec[0]['Year'],\n",
    "                 rec[0]['Volume'], rec[0]['Issue'], rec[0]['Page start'], rec[0]['Page end'])\n",
    "    if res[\"hits\"][\"total\"][\"value\"] != 0:\n",
    "        _score = res[\"hits\"][\"hits\"][0][\"_score\"]\n",
    "        if mode == 0: # tests mode (perfect case)\n",
    "            oa_doi = get_oa_doi(res[\"hits\"][\"hits\"][0]).lower()\n",
    "            sc_doi = rec[\"DOI\"].lower()\n",
    "            if parse_doi(oa_doi) == parse_doi(sc_doi):\n",
    "                return (True,res[\"hits\"][\"hits\"][0][\"_score\"])\n",
    "            else:\n",
    "                return (False,res[\"hits\"][\"hits\"][0][\"_score\"])           \n",
    "        if mode == 1: # la salida la evalua colav similarity, solo sobre el mejor hit\n",
    "            i = res[\"hits\"][\"hits\"][0]\n",
    "            value = colav_similarity(rec['Title']       ,  i[\"_source\"]['title'],\n",
    "                                    rec['Source title'],   i[\"_source\"][\"source\"],\n",
    "                                    rec['Year']        ,   i[\"_source\"]['year'],\n",
    "                                    ratio_thold=95, partial_thold=95,low_thold=82)\n",
    "            return (value,i[\"_score\"])\n",
    "#         if mode == 2: # después de los cortes la salida la evalua colav similarity\n",
    "#             if _score >= th_high:\n",
    "#                 return (True,_score)\n",
    "#             elif _score <= th_low:\n",
    "#                 return (False,_score)                \n",
    "#             else:\n",
    "#                 for i in res[\"hits\"][\"hits\"]:\n",
    "#                     paper1={}\n",
    "#                     paper1[\"title\"] = parse_string(rec[0]['Title'])\n",
    "#                     paper1[\"journal\"] = str(rec[0]['Source title'])\n",
    "#                     paper1[\"year\"] = rec[0]['Year']\n",
    "                    \n",
    "#                     paper2 = {}\n",
    "#                     paper1[\"title\"] = parse_string(i[\"_source\"]['title'])\n",
    "#                     paper1[\"journal\"] = str(i[\"_source\"][\"source\"])\n",
    "#                     paper1[\"year\"] = i[\"_source\"]['year']\n",
    "                    \n",
    "#                     value = colav_similarity(paper1, paper2   ,\n",
    "#                                             ratio_thold=99, partial_thold=98,low_thold=82)\n",
    "#                     if value:\n",
    "#                         return (True, i[\"_score\"])\n",
    "#                 return (False, i[\"_score\"])\n",
    "\n",
    "        if mode == 3: # la salida la evalua colav similarity sobre los 20 primeros hits\n",
    "            for i in res[\"hits\"][\"hits\"]:\n",
    "                paper1={}\n",
    "                paper1[\"title\"] = parse_string(rec[0]['Title'])\n",
    "                paper1[\"journal\"] = str(rec[0]['Source title'])\n",
    "                paper1[\"year\"] = rec[0]['Year']\n",
    "\n",
    "                paper2 = {}\n",
    "                paper2[\"title\"] = parse_string(i[\"_source\"]['title'])\n",
    "                paper2[\"journal\"] = str(i[\"_source\"][\"source\"])\n",
    "                paper2[\"year\"] = i[\"_source\"]['year']                \n",
    "                value = colav_similarity(paper1, paper2,\n",
    "                # value = colav_similarity(rec[0]['Title']       ,  i[\"_source\"]['title'],\n",
    "                #         rec[0]['Source title'],   i[\"_source\"][\"source\"],\n",
    "                #         rec[0]['Year']        ,   i[\"_source\"]['year'],\n",
    "                       ratio_thold=90, partial_thold=92,low_thold=81)\n",
    "#                       ratio_thold=99, partial_thold=98,low_thold=82)\n",
    "                if value:\n",
    "                    return (True, i[\"_score\"])\n",
    "                \n",
    "            return (False,_score)\n",
    "        \n",
    "        if mode == 5:\n",
    "            _score = res[\"hits\"][\"hits\"][0][\"_score\"]\n",
    "            return (rec[1],_score)\n",
    "        if mode == 6:\n",
    "            _score = res[\"hits\"][\"hits\"][0][\"_score\"]\n",
    "            if _score >= th_high:\n",
    "                return (True,_score)\n",
    "            else:\n",
    "                return (False,_score)\n",
    "#             iss1 = rec['Issue']\n",
    "#             iss2 = i[\"_source\"][\"issue\"]\n",
    "#             if iss1 and iss2:\n",
    "#                 if iss1 != iss2:\n",
    "#                     return (False, i[\"_score\"])\n",
    "    \n",
    "            # v1 = rec['Volume']\n",
    "            # v2 = i[\"_source\"][\"volume\"]\n",
    "            # if v1 and v2:\n",
    "            #     if v1 != v2:\n",
    "            #         return (False, i[\"_score\"])\n",
    "            \n",
    "            return (True, i[\"_score\"])\n",
    "        print(\"ERROR: method no valid, select 0,1,2 or 4\")\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        return (False,0)\n",
    "scopus = []\n",
    "np.random.shuffle(data[\"p\"])\n",
    "np.random.shuffle(data[\"n\"])\n",
    "for i in data[\"p\"]:#[0:10001]:\n",
    "    scopus.append((i,True))\n",
    "for i in data[\"n\"]:#[0:10000]:\n",
    "    scopus.append((i,False))\n",
    "np.random.shuffle(scopus) #shuffle is inplace\n",
    "#th_high=50  0.57 99,98,82\n",
    "th_high=500\n",
    "th_low =0\n",
    "mode = 3\n",
    "results = Parallel(n_jobs=72,backend='threading',verbose=2)(delayed(es_similarity)(rec,th_high, th_low, mode) for rec in scopus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9ffd190-2b84-439c-b549-a4ef8acbb1b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m actual \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m predicted \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mresults\u001b[49m)):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m results[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      6\u001b[0m         actual\u001b[38;5;241m.\u001b[39mappend(scopus[i][\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "#>tp, tn, fp, fn\n",
    "actual = []\n",
    "predicted = []\n",
    "for i in range(len(results)):\n",
    "    if results[i] is not None:\n",
    "        actual.append(scopus[i][1])\n",
    "        predicted.append(results[i][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2e4c07-1beb-43e7-a6ae-2027d5055f12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0b4511-b51c-4e9b-a7b6-e04db6e5b353",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(actual, predicted)\n",
    "confusion_matrix = np.flip(confusion_matrix)\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [True, False])\n",
    "\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67fdf7b-43ae-4283-a114-75fbd26f2292",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = confusion_matrix[0][1]*100/(confusion_matrix[0][0]+confusion_matrix[0][1])\n",
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eed461-93fc-4977-aaea-1493e363de48",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = confusion_matrix[1][0]*100/(confusion_matrix[1][1]+confusion_matrix[1][0])\n",
    "fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7cebbd-f4fd-4b02-ad35-4c33ebc41324",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = metrics.accuracy_score(actual,predicted)\n",
    "pre = metrics.precision_score(actual,predicted)\n",
    "rec = metrics.recall_score(actual,predicted)\n",
    "f1  = metrics.f1_score(actual,predicted)\n",
    "\n",
    "print(f\"Accuracy  = {acc:.4f}\")\n",
    "print(f\"Precision = {pre:.4f}\")\n",
    "print(f\"Recall    = {rec:.4f}\")\n",
    "print(f\"F1        = {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8501cd27-7ea5-4390-b16e-108a04ea4a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_p = []\n",
    "score_n = []\n",
    "for i in results:\n",
    "    if i[0]:\n",
    "        score_p.append(i[1])\n",
    "    else:\n",
    "        score_n.append(i[1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3119d5ae-c8f4-4f7b-ba3d-ec9455ca741e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(score_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db5db84-c1bd-4048-87f3-0f7e40d6d609",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(score_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017a8034-3216-4c1e-bcac-4a802160dc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(score_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f59e5a0-14fb-41f9-a566-d8e23b02b301",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_score_p = []\n",
    "f_score_n = []\n",
    "\n",
    "for i in score_p:\n",
    "    if i<1000:\n",
    "        f_score_p.append(i)\n",
    "\n",
    "for i in score_n:\n",
    "    if i<1000:\n",
    "        f_score_n.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ca5350-b7d7-42fa-8e8b-92d20ef724e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_score_p = np.array(f_score_p)\n",
    "f_score_n = np.array(f_score_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c2248a-38f6-40b5-b9a5-c9d6ab96473d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_score_p.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1d561f-761e-44a8-82a8-0ce58b65c82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtiene la información del histograma\n",
    "valores_p, bordes_p = np.histogram(f_score_p, bins=100, density=True)\n",
    "centros_p = 0.5 * (bordes_p[:-1] + bordes_p[1:])\n",
    "\n",
    "# Encuentra el valor máximo en el eje Y\n",
    "valor_maximo_y_p = max(valores_p)\n",
    "\n",
    "# Encuentra el valor en el eje X para el cual Y es máximo\n",
    "valor_maximo_x_p = centros_p[np.argmax(valores_p)]\n",
    "valor_maximo_x_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8bc200-548f-4cce-b768-6652bb6891c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtiene la información del histograma\n",
    "valores_n, bordes_n = np.histogram(f_score_n, bins=100, density=True)\n",
    "centros_n = 0.5 * (bordes_n[:-1] + bordes_n[1:])\n",
    "\n",
    "# Encuentra el valor máximo en el eje Y\n",
    "valor_maximo_y_n = max(valores_n)\n",
    "\n",
    "# Encuentra el valor en el eje X para el cual Y es máximo\n",
    "valor_maximo_x_n = centros_p[np.argmax(valores_n)]\n",
    "valor_maximo_x_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3828cd-3eb9-4c75-9fdd-b6a782e67b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 100\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(f_score_p, bins=100, alpha=0.5, label=\"data1\", density=False)\n",
    "plt.hist(f_score_n, bins=100, alpha=0.5, label=\"data1\", density=False)\n",
    "# Dibuja una línea vertical en el punto máximo\n",
    "plt.axvline(x=valor_maximo_x_p, color='r', linestyle='--', label=f'Máximo en X: {valor_maximo_x_p:.2f}')\n",
    "plt.axvline(x=valor_maximo_x_n, color='r', linestyle='--', label=f'Máximo en X: {valor_maximo_x_n:.2f}')\n",
    "\n",
    "True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eafcc7a-a6d0-44d0-bf09-b22568bfb16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scopus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c07b47b-19bf-4bd1-aad5-893a73f578e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = scopus[0:2]\n",
    "title = [parse_string(rec[0][0]['Title']), parse_string(rec[1][0]['Title'])]\n",
    "res = search(title,\", \".join(rec[0][0]['Authors'].split(\",\")[0:5]),rec[0][0]['Source title'],rec[0][0]['Year'],\n",
    "                 rec[0][0]['Volume'], rec[0][0]['Issue'], rec[0][0]['Page start'], rec[0][0]['Page end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d08ca4-342c-4fd1-a8ca-f19fa79aedd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a45bed6-abef-4cd7-8dab-7f50842ec26b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d6a0bb-23a5-4d77-b185-9f2b3649846d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
