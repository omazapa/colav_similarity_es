{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18f96b9d-566c-47f1-a2a4-bf26a5205c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mohan.Similarity import Similarity\n",
    "from mohan.ColavSimilarity import parse_doi, parse_string\n",
    "from joblib import Parallel, delayed\n",
    "import pickle\n",
    "import numpy as np\n",
    "from mohan.ColavSimilarity import ColavSimilarity, parse_doi, parse_string\n",
    "from elasticsearch import Elasticsearch, __version__ as es_version\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from pymongo import MongoClient\n",
    "import copy\n",
    "from IPython.display import JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eb47df-f5d2-4141-9156-a5e6b8870b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "openalex = list(MongoClient()[\"openalexco\"][\"works\"].find({'doi': {\"$ne\": None}}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2a09318-0b89-471a-9766-d4434542d7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from mohan.ColavSimilarity import ColavSimilarity, parse_string\n",
    "from elasticsearch import Elasticsearch, __version__ as es_version\n",
    "from elasticsearch.helpers import bulk\n",
    "\n",
    "\n",
    "class Similarity:\n",
    "    def __init__(self, es_index, es_uri: str = \"http://localhost:9200\",\n",
    "                 es_auth: tuple = ('elastic', 'colav'),\n",
    "                 es_req_timeout: int = 120):\n",
    "        \"\"\"\n",
    "        Initialize the Similarity class.\n",
    "        Parameters:\n",
    "        -----------\n",
    "        es_index: str \n",
    "                name of the index\n",
    "        es_uri: str \n",
    "                uri of the elastic search server\n",
    "        es_auth: tuple \n",
    "                authentication for the elastic search server\n",
    "        es_req_timeout: int \n",
    "                elastic search request timeout\n",
    "        \"\"\"\n",
    "        auth = es_auth\n",
    "        if es_version[0] < 8:\n",
    "            self.es = Elasticsearch(\n",
    "                es_uri, http_auth=auth, timeout=es_req_timeout)\n",
    "        else:\n",
    "            self.es = Elasticsearch(\n",
    "                es_uri, basic_auth=auth, timeout=es_req_timeout)\n",
    "        self.es_index = es_index\n",
    "        self.es_req_timeout = es_req_timeout\n",
    "\n",
    "    def ensure_index(self, mapping: dict = None, recreate: bool = False):\n",
    "        \"\"\"\n",
    "        Create an index.\n",
    "        Parameters:\n",
    "        -----------\n",
    "        index_name: str name of the index\n",
    "        mapping: dict mapping of the index\n",
    "        recreate: bool whether to recreate the index or not\n",
    "\n",
    "        \"\"\"\n",
    "        if recreate:\n",
    "            if self.es.indices.exists(index=self.es_index):\n",
    "                self.delete_index(self.es_index)\n",
    "        if mapping:\n",
    "            self.es.indices.create(index=self.es_index, body=mapping)\n",
    "        else:\n",
    "            self.es.indices.create(index=self.es_index)\n",
    "\n",
    "    def delete_index(self, index_name: str):\n",
    "        \"\"\"\n",
    "        Delete an index.\n",
    "        Parameters:\n",
    "        -----------\n",
    "        index_name: str name of the index\n",
    "        \"\"\"\n",
    "        self.es.indices.delete(index=index_name)\n",
    "\n",
    "    def insert_work(self, _id: str, work: dict):\n",
    "        \"\"\"\n",
    "        Insert a work into the index.\n",
    "        work should have a dict structure like the next one.\n",
    "        work = {\"title\": \"title of the work\",\n",
    "                \"authors\": \"authors of the work\",\n",
    "                \"source\": \"source of the work\",\n",
    "                \"year\": \"year of the work\",\n",
    "                \"volume\": \"volume of the work\",\n",
    "                \"issue\": \"issue of the work\",\n",
    "                \"page_start\": \"page start of the work\",\n",
    "                \"page_end\": \"page end of the work\"}\n",
    "        every value is a string, including the year, volume, issue, page_start and page_end.\n",
    "\n",
    "        Additional fields such as doi, pmid, pmcid, etc. can be added to the work dict if needed,\n",
    "        but the search is over the previous fields.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        _id: str id of the work (ex: mongodb id as string)\n",
    "        work: dict work to be inserted\n",
    "        \"\"\"\n",
    "        return self.es.index(index=self.es_index,  id=_id, document=work)\n",
    "\n",
    "    def search_work(self, title: str, source: str, year: str,\n",
    "                    volume: str, issue: str, page_start: str, page_end: str, \n",
    "                    use_es_thold: bool = False, es_thold_low: int = 0, es_thold_high: int = 120,\n",
    "                    ratio_thold: int = 90, partial_thold: int = 95, low_thold: int = 80, parse_title: bool = True):\n",
    "        \"\"\"\n",
    "        Compare two papers to know if they are the same or not.\n",
    "        Parameters:\n",
    "        -----------\n",
    "        title: str \n",
    "                title of the paper\n",
    "        source: str \n",
    "                name of the journal in which the paper was published\n",
    "        year: int \n",
    "                year in which the paper was published\n",
    "        volume: int \n",
    "                volume of the journal in which the paper was published\n",
    "        issue: int \n",
    "                issue of the journal in which the paper was published\n",
    "        page_start: int \n",
    "                first page of the paper\n",
    "        page_end: int \n",
    "                last page of the paper\n",
    "        use_es_thold: bool\n",
    "                whether to use the elastic search score threshold or not\n",
    "        es_thold_low: int\n",
    "                elastic search score threshold to discard some results with lower score values\n",
    "        es_thold_high: int\n",
    "                elastic search score threshold to return the best hit\n",
    "        ratio_thold: int \n",
    "                threshold to compare through ratio function in thefuzz library\n",
    "        partial_ratio_thold: int \n",
    "                threshold to compare through partial_ratio function in thefuzz library\n",
    "        low_thold: int\n",
    "                threshold to discard some results with lower score values\n",
    "        es_request_timeout: int\n",
    "                elastic search request timeout\n",
    "        parse_title: bool\n",
    "                whether to parse the title or not (parse title helps to improve the results)\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        record: dict when the papers are (potentially) the same, None otherwise.\n",
    "        \"\"\"\n",
    "        if not isinstance(title, str):\n",
    "            title = \"\"\n",
    "\n",
    "        if not isinstance(source, str):\n",
    "            source = \"\"\n",
    "\n",
    "        if isinstance(volume, int):\n",
    "            volume = str(volume)\n",
    "\n",
    "        if isinstance(issue, int):\n",
    "            issue = str(issue)\n",
    "\n",
    "        if isinstance(page_start, int):\n",
    "            page_start = str(page_start)\n",
    "\n",
    "        if isinstance(page_end, int):\n",
    "            page_end = str(page_end)\n",
    "\n",
    "        if not isinstance(volume, str):\n",
    "            volume = \"\"\n",
    "\n",
    "        if not isinstance(issue, str):\n",
    "            issue = \"\"\n",
    "\n",
    "        if not isinstance(page_start, str):\n",
    "            page_start = \"\"\n",
    "\n",
    "        if not isinstance(page_end, str):\n",
    "            page_end = \"\"\n",
    "        if parse_title:\n",
    "            title = parse_string(title)\n",
    "        # body = {\n",
    "        #     \"query\": {\n",
    "        #         \"bool\": {\n",
    "        #             \"should\": [\n",
    "        #                 {\"match\": {\"title\": {\"query\":  title,\"boost\": 0.9}}},\n",
    "        #                 {\"match\": {\"source\":  source}},\n",
    "        #                 {\"term\":  {\"year\": year}},\n",
    "        #                 {\"term\":  {\"volume\": volume}},\n",
    "        #                 {\"term\":  {\"issue\": issue}},\n",
    "        #                 {\"term\":  {\"page_start\": page_start}},\n",
    "        #                 {\"term\":  {\"page_end\": page_end}},\n",
    "        #             ],\n",
    "        #         }\n",
    "        #     },\n",
    "        #     \"size\": 20,\n",
    "        # }\n",
    "        body = {\n",
    "            \"query\": {\n",
    "                \"bool\": {\n",
    "                    \"should\": [\n",
    "                        {\"match\": { \"title\":  {\n",
    "                                 \"query\": title,\n",
    "                                 \"operator\": \"OR\"\n",
    "                              }}},\n",
    "                        #{\"match\": {\"title\": {\"query\":  title,\"boost\": 1}}},\n",
    "                        # {\"match\": {\"source\":  source}},\n",
    "                        { \"match\": { \"source\":  {\n",
    "                                 \"query\": source,\n",
    "                                 \"operator\": \"AND\"\n",
    "                              }}},\n",
    "                        {\"term\":  {\"year\": year}},\n",
    "                        {\"term\":  {\"volume\": volume}},\n",
    "                        {\"term\":  {\"issue\": issue}},\n",
    "                        {\"term\":  {\"page_start\": page_start}},\n",
    "                        {\"term\":  {\"page_end\": page_end}},\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "            \"size\": 20\n",
    "        }\n",
    "        res = self.es.search(index=self.es_index, **body)\n",
    "        if res[\"hits\"][\"total\"][\"value\"] != 0:\n",
    "            best_hit = res[\"hits\"][\"hits\"][0]\n",
    "            if use_es_thold:\n",
    "                if best_hit[\"_score\"] >= es_thold_high:\n",
    "                    return best_hit\n",
    "\n",
    "            # for i in res[\"hits\"][\"hits\"]:\n",
    "            #     value = ColavSimilarity(title, i[\"_source\"][\"title\"],\n",
    "            #                             source, i[\"_source\"][\"source\"],\n",
    "            #                             year, i[\"_source\"][\"year\"],\n",
    "            #                             ratio_thold=ratio_thold, partial_thold=partial_thold, low_thold=low_thold)\n",
    "            #     if value:\n",
    "            #         return i\n",
    "            return None\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def insert_bulk(self, entries: list, refresh=True):\n",
    "        \"\"\"\n",
    "        Insert a bulk of works into the index.\n",
    "        Parameters:\n",
    "        -----------\n",
    "        entries: list \n",
    "                list of works to be inserted\n",
    "        \"\"\"\n",
    "        return bulk(self.es, entries, index=self.es_index, refresh=refresh, request_timeout=self.es_req_timeout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9119c5e-1f2d-462b-9f67-8115c6493fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Similarity(\"openalex_scratch\",es_uri=\"172.19.31.8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48db2084-2ab4-462b-8bf4-8d421673c5e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4656340-57ac-47e9-8f96-4d95df289871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "517909ce-0c26-475f-8f93-75ce8daf759f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.ensure_index(recreate=True)\n",
    "def search(i):\n",
    "    title = parse_string(i[\"title\"])\n",
    "    source = i[\"host_venue\"][\"display_name\"]\n",
    "    year = i[\"publication_year\"]\n",
    "    volume = i[\"biblio\"][\"volume\"] \n",
    "    issue = i[\"biblio\"][\"issue\"] \n",
    "    first_page = i[\"biblio\"][\"first_page\"]\n",
    "    last_page = i[\"biblio\"][\"last_page\"]\n",
    "    \n",
    "    res = s.search_work(title,source,year,volume,issue,first_page,last_page,\n",
    "                        use_es_thold = True, es_thold_low = 0, es_thold_high = 150)\n",
    "    if res is not None:\n",
    "        return (i,res)\n",
    "    else:\n",
    "        work = {}\n",
    "        work[\"title\"] = parse_string(i[\"title\"])\n",
    "        work[\"source\"] = i[\"host_venue\"][\"display_name\"]\n",
    "        work[\"year\"] = i[\"publication_year\"]\n",
    "        work[\"volume\"] = i[\"biblio\"][\"volume\"] \n",
    "        work[\"issue\"] = i[\"biblio\"][\"issue\"] \n",
    "        work[\"first_page\"] = i[\"biblio\"][\"first_page\"]\n",
    "        work[\"last_page\"] = i[\"biblio\"][\"last_page\"]\n",
    "        work[\"doi\"] = i[\"doi\"]\n",
    "        _id = str(i[\"_id\"])\n",
    "        s.insert_work(_id,work)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "76e9410c-9398-417b-a6d6-8f2d02ee0ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=72)]: Using backend ThreadingBackend with 72 concurrent workers.\n",
      "[Parallel(n_jobs=72)]: Done  18 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=72)]: Done 221 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=72)]: Done 504 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=72)]: Done 869 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=72)]: Done 1314 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=72)]: Done 1841 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=72)]: Done 2448 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=72)]: Done 3137 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=72)]: Done 3906 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=72)]: Done 4757 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=72)]: Done 5688 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=72)]: Done 6701 tasks      | elapsed:   22.5s\n",
      "[Parallel(n_jobs=72)]: Done 7794 tasks      | elapsed:   26.1s\n",
      "[Parallel(n_jobs=72)]: Done 8969 tasks      | elapsed:   29.9s\n",
      "[Parallel(n_jobs=72)]: Done 10224 tasks      | elapsed:   34.0s\n",
      "[Parallel(n_jobs=72)]: Done 11561 tasks      | elapsed:   38.4s\n",
      "[Parallel(n_jobs=72)]: Done 12978 tasks      | elapsed:   43.1s\n",
      "[Parallel(n_jobs=72)]: Done 14477 tasks      | elapsed:   48.0s\n",
      "[Parallel(n_jobs=72)]: Done 16056 tasks      | elapsed:   53.1s\n",
      "[Parallel(n_jobs=72)]: Done 17717 tasks      | elapsed:   58.6s\n",
      "[Parallel(n_jobs=72)]: Done 19458 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=72)]: Done 21281 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=72)]: Done 23184 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=72)]: Done 25169 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=72)]: Done 27234 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=72)]: Done 29381 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=72)]: Done 31608 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=72)]: Done 33917 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=72)]: Done 36306 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=72)]: Done 38777 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=72)]: Done 41328 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=72)]: Done 43961 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=72)]: Done 46674 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=72)]: Done 49469 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=72)]: Done 52344 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=72)]: Done 55301 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=72)]: Done 58338 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=72)]: Done 61457 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=72)]: Done 64656 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=72)]: Done 67937 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=72)]: Done 71298 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=72)]: Done 74741 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=72)]: Done 78264 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=72)]: Done 81869 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=72)]: Done 85554 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=72)]: Done 89321 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=72)]: Done 93168 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=72)]: Done 97097 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=72)]: Done 101106 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=72)]: Done 105197 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=72)]: Done 109368 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=72)]: Done 113621 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=72)]: Done 117954 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=72)]: Done 122369 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=72)]: Done 126864 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=72)]: Done 131441 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=72)]: Done 136098 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=72)]: Done 140837 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=72)]: Done 145656 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=72)]: Done 150557 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=72)]: Done 155538 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=72)]: Done 160601 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=72)]: Done 165744 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=72)]: Done 170969 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=72)]: Done 176274 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=72)]: Done 181661 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=72)]: Done 187128 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=72)]: Done 192677 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=72)]: Done 198306 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=72)]: Done 203863 out of 203863 | elapsed: 11.6min finished\n"
     ]
    }
   ],
   "source": [
    "results = Parallel(n_jobs=72,backend='threading',verbose=2)(delayed(search)(i) for i in openalex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "beee123d-184c-4ab8-95fa-a639b144e5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [i for i in results if i is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "36447c2e-99cd-47c1-81a3-7130a139e233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.02256417299853333"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2655 1.302\n",
    "# 294 no colav simi th = 100\n",
    "print(len(res))\n",
    "len(res)*100/len(openalex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a409f40-961b-4ded-a9e5-aebe126e5fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('openalex_fails_noauthors_rt90_pt92_lt81.pkl', 'wb') as f:\n",
    "    pickle.dump({\"fails\":res}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c22b43c3-9763-4f35-ba48-0797bcd1be86",
   "metadata": {},
   "outputs": [],
   "source": [
    "res[0][0][\"_id\"] = str(res[0][0][\"_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d3559348-c64d-421e-8e5b-0060216d642d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "_id": "637cfbbf244b9f9d0fe4d445",
       "alternate_host_venues": [],
       "authorships": [
        {
         "author": {
          "display_name": "Braulio Insuasty O.",
          "id": "https://openalex.org/A2135680217",
          "orcid": null
         },
         "author_position": "first",
         "institutions": [
          {
           "country_code": "CO",
           "display_name": "University of Valle",
           "id": "https://openalex.org/I91732220",
           "ror": "https://ror.org/00jb9vg53",
           "type": "education"
          }
         ],
         "raw_affiliation_string": "Department of Chemistry, Universidad del Valle, A. A 25360, Cali (Colombia)"
        },
        {
         "author": {
          "display_name": "Henry Insuasty I.",
          "id": "https://openalex.org/A2133992910",
          "orcid": null
         },
         "author_position": "middle",
         "institutions": [
          {
           "country_code": "CO",
           "display_name": "University of Valle",
           "id": "https://openalex.org/I91732220",
           "ror": "https://ror.org/00jb9vg53",
           "type": "education"
          }
         ],
         "raw_affiliation_string": "Department of Chemistry, Universidad del Valle, A. A 25360, Cali (Colombia)"
        },
        {
         "author": {
          "display_name": "Jairo Quiroga P.",
          "id": "https://openalex.org/A2578366590",
          "orcid": null
         },
         "author_position": "middle",
         "institutions": [
          {
           "country_code": "CO",
           "display_name": "University of Valle",
           "id": "https://openalex.org/I91732220",
           "ror": "https://ror.org/00jb9vg53",
           "type": "education"
          }
         ],
         "raw_affiliation_string": "Department of Chemistry, Universidad del Valle, A. A 25360, Cali (Colombia)"
        },
        {
         "author": {
          "display_name": "Claudio Saitz",
          "id": "https://openalex.org/A2269682847",
          "orcid": null
         },
         "author_position": "middle",
         "institutions": [
          {
           "country_code": "CL",
           "display_name": "University of Chile",
           "id": "https://openalex.org/I69737025",
           "ror": "https://ror.org/047gc3g35",
           "type": "education"
          }
         ],
         "raw_affiliation_string": "Departamento de Química Orgánica y Fisico‐Química, Universidad de Chile, Casilla 233, Santiago 1, Chile"
        },
        {
         "author": {
          "display_name": "Carolina Jullian",
          "id": "https://openalex.org/A2077697955",
          "orcid": "https://orcid.org/0000-0001-6902-7170"
         },
         "author_position": "last",
         "institutions": [
          {
           "country_code": "CL",
           "display_name": "University of Chile",
           "id": "https://openalex.org/I69737025",
           "ror": "https://ror.org/047gc3g35",
           "type": "education"
          }
         ],
         "raw_affiliation_string": "CEPEDEQ, Facultad de Ciencias Químicas y Farmaceúticas, Universidad de Chile, Casilla 233 Santiago 1 - Chile"
        }
       ],
       "biblio": {
        "first_page": "635",
        "issue": "3",
        "last_page": "638",
        "volume": "36"
       },
       "cited_by_api_url": "https://api.openalex.org/works?filter=cites:W2054753607",
       "cited_by_count": 14,
       "concepts": [
        {
         "display_name": "Chemistry",
         "id": "https://openalex.org/C185592680",
         "level": 0,
         "score": "0.932825",
         "wikidata": "https://www.wikidata.org/wiki/Q2329"
        },
        {
         "display_name": "Aryl",
         "id": "https://openalex.org/C2781076698",
         "level": 3,
         "score": "0.665938",
         "wikidata": "https://www.wikidata.org/wiki/Q718074"
        },
        {
         "display_name": "Medicinal chemistry",
         "id": "https://openalex.org/C155647269",
         "level": 1,
         "score": "0.657731",
         "wikidata": "https://www.wikidata.org/wiki/Q243455"
        }
       ],
       "counts_by_year": [
        {
         "cited_by_count": 1,
         "year": 2020
        },
        {
         "cited_by_count": 1,
         "year": 2017
        },
        {
         "cited_by_count": 1,
         "year": 2014
        }
       ],
       "created_date": "2016-06-24",
       "display_name": "Reaction of 4,5-diamino-3-methyl-1-phenylpyrazole with 3- dimethylaminopropiophenones. Synthesis of new 4-aryl-6-methyl-8-phenyl-2,3- dihydropyrazolo[3,4-b]diazepines and 4-aryl-8-methyl-6-phenyl-2,3- dihydropyrazolo[4,3-b]diazepines",
       "doi": "https://doi.org/10.1002/jhet.5570360310",
       "host_venue": {
        "display_name": "Journal of Heterocyclic Chemistry",
        "id": "https://openalex.org/V46134040",
        "is_oa": false,
        "issn": [
         "0022-152X",
         "1943-5193"
        ],
        "issn_l": "0022-152X",
        "license": null,
        "publisher": "Wiley",
        "type": "publisher",
        "url": "https://doi.org/10.1002/jhet.5570360310",
        "version": null
       },
       "id": "https://openalex.org/W2054753607",
       "ids": {
        "doi": "https://doi.org/10.1002/jhet.5570360310",
        "mag": "2054753607",
        "openalex": "https://openalex.org/W2054753607"
       },
       "is_paratext": false,
       "is_retracted": false,
       "mesh": [],
       "open_access": {
        "is_oa": false,
        "oa_status": "closed",
        "oa_url": null
       },
       "publication_date": "1999-05-01",
       "publication_year": 1999,
       "referenced_works": [
        "https://openalex.org/W2949659920",
        "https://openalex.org/W2508473624",
        "https://openalex.org/W2002871512",
        "https://openalex.org/W2952081936",
        "https://openalex.org/W2951228656",
        "https://openalex.org/W2025632879",
        "https://openalex.org/W2091199122",
        "https://openalex.org/W124991102",
        "https://openalex.org/W2038633289",
        "https://openalex.org/W2949967432",
        "https://openalex.org/W2953325207",
        "https://openalex.org/W2921073505"
       ],
       "related_works": [],
       "title": "Reaction of 4,5-diamino-3-methyl-1-phenylpyrazole with 3- dimethylaminopropiophenones. Synthesis of new 4-aryl-6-methyl-8-phenyl-2,3- dihydropyrazolo[3,4-b]diazepines and 4-aryl-8-methyl-6-phenyl-2,3- dihydropyrazolo[4,3-b]diazepines",
       "type": "journal-article",
       "updated_date": "2021-11-03"
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JSON(res[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4fbd0b7-ba13-456a-8a61-f6a847fb1fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "_id": "637cfbbf244b9f9d0fe4d1e2",
       "_index": "openalex_scratch",
       "_score": 143.84381,
       "_source": {
        "doi": "https://doi.org/10.1002/chin.199944171",
        "first_page": null,
        "issue": "44",
        "last_page": null,
        "source": "ChemInform",
        "title": "reaction of 4,5-diamino-3-methyl-1-phenylpyrazole with 3-dimethylaminopropiophenones. synthesis of new 4-aryl-6-methyl-8-phenyl-2,3-dihydropyrazolo[3,4-b]diazepines (iii) and 4-aryl-8-methyl-6-phenyl-2,3-dihydropyrazolo[4,3-b]diazepines (iv).",
        "volume": "30",
        "year": 1999
       }
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JSON(res[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56813e58-9a78-4734-a640-023e624fe846",
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = search(res[100][\"_source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffc281b-e516-47e1-a23b-2171c915fb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037ad3b2-b3ad-4031-8ccf-ad6392d78abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in openalex:\n",
    "    if \"https://doi.org/10.1007/jhep01(2011)080\" == i[\"doi\"]:\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db368c81-08d4-4298-b773-222a383a97e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6907524-684d-4a09-833d-a8417f8d5303",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(openalex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70869294-baf1-4b73-8a0c-8f907eb81938",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
